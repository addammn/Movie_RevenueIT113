{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27956c3",
   "metadata": {},
   "source": [
    "\n",
    "# ITI113 — Two-Model Training (Colab + Google Drive)\n",
    "This notebook is **user-friendly** and **Drive-aware**. It will:\n",
    "- Mount your Google Drive (you'll authorize with **your own account**).\n",
    "- Use (or create) a folder called **`Movie_IT113`** inside your Drive.\n",
    "- Train **two models** (baseline vs stronger) on a CSV.\n",
    "- Save all outputs to `Movie_IT113/artifacts/` in your Drive so your teammate/lecturer can see them.\n",
    "\n",
    "> If you're Calvin or the lecturer: open this notebook from the shared Drive folder. You'll be asked to mount **your own Drive**. As long as you have access to the folder, it works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa487b",
   "metadata": {},
   "source": [
    "## 0) Setup (install packages, mount Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, install dependencies and mount Drive\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install pandas scikit-learn joblib\n",
    "    from google.colab import drive\n",
    "    print(\"Mounting your Google Drive… (you'll authorize with your own Google account)\")\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "print(\"Ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e468de0",
   "metadata": {},
   "source": [
    "## 1) Choose your project folder in Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pandas as pd\n",
    "\n",
    "# Default to My Drive/Movie_IT113; change this if your shared folder is elsewhere.\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\" if 'IN_COLAB' in globals() and IN_COLAB else \".\"\n",
    "PROJECT_DIR = os.path.join(DRIVE_ROOT, \"Movie_IT113\")\n",
    "\n",
    "# If the folder doesn't exist, create it (safe operation). If you're using a shared folder,\n",
    "# you can replace PROJECT_DIR with the exact path to that folder inside your Drive.\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "ART_DIR = os.path.join(PROJECT_DIR, \"artifacts\")\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Project directory:\", PROJECT_DIR)\n",
    "print(\"Artifacts directory:\", ART_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a13d7b",
   "metadata": {},
   "source": [
    "## 2) Dataset — use the demo CSV or replace with your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already placed a CSV in the Movie_IT113 folder, set CSV_NAME to that file.\n",
    "# Otherwise, we'll create a small realistic demo CSV for you.\n",
    "CSV_NAME = \"movie_boxoffice_demo.csv\"    # you can change this to your dataset file name\n",
    "CSV_PATH = os.path.join(PROJECT_DIR, CSV_NAME)\n",
    "TARGET   = \"revenue\"                      # for the demo we use a regression target\n",
    "\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    # Create a small realistic demo dataset\n",
    "    import numpy as np\n",
    "    rng = np.random.default_rng(42)\n",
    "    n = 400\n",
    "    genres = [\"Action\",\"Comedy\",\"Drama\",\"Horror\",\"Romance\",\"Sci-Fi\",\"Animation\"]\n",
    "    genre_effect = {\"Action\":25.0,\"Comedy\":10.0,\"Drama\":5.0,\"Horror\":8.0,\"Romance\":6.0,\"Sci-Fi\":22.0,\"Animation\":15.0}\n",
    "    franchises = [\"none\",\"weak\",\"strong\"]\n",
    "    fran_effect = {\"none\":0.0,\"weak\":18.0,\"strong\":60.0}\n",
    "\n",
    "    budget = rng.uniform(5, 200, size=n)\n",
    "    runtime = np.clip(rng.normal(110, 18, size=n), 80, 180)\n",
    "    popularity = rng.uniform(0, 50, size=n)\n",
    "    vote_avg = rng.uniform(3.0, 8.5, size=n)\n",
    "    genre = rng.choice(genres, size=n)\n",
    "    release_month = rng.integers(1, 13, size=n)\n",
    "    is_sequel = (rng.random(n) < 0.25).astype(int)\n",
    "    franchise = rng.choice(franchises, size=n, p=[0.6,0.25,0.15])\n",
    "\n",
    "    season_uplift = (np.isin(release_month, [5,6,7,8]) * 15.0).astype(float)\n",
    "    season_uplift += (np.isin(release_month, [11,12]) * 8.0).astype(float)\n",
    "    noise = rng.normal(0, 30.0, size=n)\n",
    "\n",
    "    revenue = (\n",
    "        1.2 * budget +\n",
    "        1.5 * popularity +\n",
    "        5.0 * (vote_avg - 5.0) +\n",
    "        0.10 * (runtime - 110.0) +\n",
    "        (is_sequel * 40.0) +\n",
    "        np.vectorize(genre_effect.get)(genre) +\n",
    "        season_uplift +\n",
    "        np.vectorize(fran_effect.get)(franchise) +\n",
    "        noise\n",
    "    )\n",
    "    revenue = np.maximum(revenue, 0.5)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"budget_musd\": np.round(budget, 2),\n",
    "        \"runtime_min\": np.round(runtime, 0).astype(int),\n",
    "        \"popularity\": np.round(popularity, 2),\n",
    "        \"vote_average\": np.round(vote_avg, 2),\n",
    "        \"genre\": genre,\n",
    "        \"release_month\": release_month,\n",
    "        \"is_sequel\": is_sequel,\n",
    "        \"franchise_strength\": franchise,\n",
    "        \"revenue\": np.round(revenue, 2),\n",
    "    })\n",
    "    df.to_csv(CSV_PATH, index=False)\n",
    "    print(f\"Demo CSV created at: {CSV_PATH}\")\n",
    "else:\n",
    "    print(f\"Using existing CSV at: {CSV_PATH}\")\n",
    "\n",
    "# Quick peek\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "display(df.head(3))\n",
    "print(\"Columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53df41",
   "metadata": {},
   "source": [
    "## 3) Train two models (baseline vs strong) and save to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os, json\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from joblib import dump\n",
    "\n",
    "def basic_clean(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    drop = []\n",
    "    for c in X.columns:\n",
    "        if X[c].isna().all() or X[c].nunique(dropna=False) <= 1:\n",
    "            drop.append(c)\n",
    "    if drop:\n",
    "        X = X.drop(columns=drop)\n",
    "    return X\n",
    "\n",
    "def infer_task(y: pd.Series) -> str:\n",
    "    if pd.api.types.is_numeric_dtype(y):\n",
    "        return \"regression\" if y.nunique(dropna=True) > 10 else \"classification\"\n",
    "    return \"classification\"\n",
    "\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    task = infer_task(y)\n",
    "    strat = y if task == \"classification\" else None\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=strat)\n",
    "\n",
    "# Load & split\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if \"revenue\" not in df.columns:\n",
    "    raise ValueError(\"Expected 'revenue' as target for this demo. Change TARGET if using your own CSV.\")\n",
    "y = df[\"revenue\"]\n",
    "X = basic_clean(df.drop(columns=[\"revenue\"]))\n",
    "\n",
    "num_cols = [c for c in X.columns if is_numeric_dtype(X[c])]\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                     (\"scaler\", StandardScaler(with_mean=True))])\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "pre = ColumnTransformer([(\"num\", num_pipe, num_cols),\n",
    "                         (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Two models for regression\n",
    "modelA_name, modelA = \"linreg\", LinearRegression()\n",
    "modelB_name, modelB = \"rf_reg\", RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "\n",
    "pipeA = make_pipeline(pre, modelA)\n",
    "pipeB = make_pipeline(pre, modelB)\n",
    "\n",
    "pipeA.fit(X_train, y_train)\n",
    "pipeB.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "def eval_regression(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return {\"rmse\": float(mse**0.5), \"mae\": float(mean_absolute_error(y_true, y_pred)), \"r2\": float(r2_score(y_true, y_pred))}\n",
    "\n",
    "yA = pipeA.predict(X_test)\n",
    "yB = pipeB.predict(X_test)\n",
    "mA = eval_regression(y_test, yA)\n",
    "mB = eval_regression(y_test, yB)\n",
    "\n",
    "# Save artifacts to Drive\n",
    "dump(pipeA, os.path.join(ART_DIR, \"model_A.joblib\"))\n",
    "dump(pipeB, os.path.join(ART_DIR, \"model_B.joblib\"))\n",
    "with open(os.path.join(ART_DIR, \"metrics_A.json\"),\"w\") as f: json.dump(mA,f,indent=2)\n",
    "with open(os.path.join(ART_DIR, \"metrics_B.json\"),\"w\") as f: json.dump(mB,f,indent=2)\n",
    "with open(os.path.join(ART_DIR, \"feature_columns.json\"),\"w\") as f: json.dump({\"columns\": list(X_train.columns)}, f, indent=2)\n",
    "\n",
    "import pandas as pd\n",
    "keys = sorted(set(list(mA.keys()) + list(mB.keys())))\n",
    "cmp = pd.DataFrame([[mA.get(k,None) for k in keys],[mB.get(k,None) for k in keys]],\n",
    "                   columns=keys, index=[modelA_name, modelB_name])\n",
    "display(cmp)\n",
    "\n",
    "print(\"Artifacts saved in:\", ART_DIR)\n",
    "print(\"Files:\", os.listdir(ART_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a207b75d",
   "metadata": {},
   "source": [
    "## 4) (Optional) Change folder path if your shared folder lives elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae80963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your shared folder is NOT in MyDrive/Movie_IT113, set PROJECT_DIR manually, e.g.:\n",
    "# PROJECT_DIR = \"/content/drive/Shareddrives/<YourSharedDriveName>/Movie_IT113\"\n",
    "# ART_DIR = os.path.join(PROJECT_DIR, \"artifacts\")\n",
    "# Then re-run the training cell above to save artifacts there.\n",
    "print(\"If you need to change folder location, edit PROJECT_DIR above and re-run the training cell.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
